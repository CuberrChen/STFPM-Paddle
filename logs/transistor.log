/home/aistudio/STFPM-main
W0412 00:04:19.645674 23546 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1
W0412 00:04:19.650342 23546 device_context.cc:465] device: 0, cuDNN Version: 7.6.
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:04:40	Epoch 0[32/170]: loss:3.64506, lr:0.40000, batch time:0.0853, data time:0.2064
2022-04-12 00:04:40	Epoch 0[96/170]: loss:3.22987, lr:0.40000, batch time:0.0536, data time:0.1907
2022-04-12 00:04:41	Epoch 0[160/170]: loss:2.71796, lr:0.40000, batch time:0.0548, data time:0.1827
2022-04-12 00:04:41	Epoch 0 training ends, total 1.31s
2022-04-12 00:04:41	Epoch 0 testing start
2022-04-12 00:04:41	Valid Loss: 2.7207443
2022-04-12 00:04:45	Epoch: 0	Catergory: transistor	Pixel-AUC: 0.437928	Image-AUC: 0.570417
2022-04-12 00:04:45	Epoch 0 testing end, total 4.60s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:04:45	Epoch 1[32/170]: loss:2.22434, lr:0.40000, batch time:0.0669, data time:0.2003
2022-04-12 00:04:46	Epoch 1[96/170]: loss:1.86966, lr:0.40000, batch time:0.0519, data time:0.1865
2022-04-12 00:04:46	Epoch 1[160/170]: loss:1.60751, lr:0.40000, batch time:0.0513, data time:0.1875
2022-04-12 00:04:46	Epoch 1 training ends, total 1.28s
2022-04-12 00:04:46	Epoch 1 testing start
2022-04-12 00:04:47	Valid Loss: 1.6181866
2022-04-12 00:04:51	Epoch: 1	Catergory: transistor	Pixel-AUC: 0.602552	Image-AUC: 0.621667
2022-04-12 00:04:51	Epoch 1 testing end, total 4.54s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:04:51	Epoch 2[32/170]: loss:1.44055, lr:0.40000, batch time:0.0311, data time:0.1991
2022-04-12 00:04:52	Epoch 2[96/170]: loss:1.35131, lr:0.40000, batch time:0.0522, data time:0.1871
2022-04-12 00:04:52	Epoch 2[160/170]: loss:1.23016, lr:0.40000, batch time:0.0540, data time:0.1853
2022-04-12 00:04:52	Epoch 2 training ends, total 1.27s
2022-04-12 00:04:52	Epoch 2 testing start
2022-04-12 00:04:53	Valid Loss: 0.6592424
2022-04-12 00:04:57	Epoch: 2	Catergory: transistor	Pixel-AUC: 0.697629	Image-AUC: 0.576667
2022-04-12 00:04:57	Epoch 2 testing end, total 4.51s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:04:57	Epoch 3[32/170]: loss:1.14632, lr:0.40000, batch time:0.0311, data time:0.2003
2022-04-12 00:04:58	Epoch 3[96/170]: loss:1.10395, lr:0.40000, batch time:0.0556, data time:0.1851
2022-04-12 00:04:58	Epoch 3[160/170]: loss:1.05318, lr:0.40000, batch time:0.0515, data time:0.1837
2022-04-12 00:04:58	Epoch 3 training ends, total 1.28s
2022-04-12 00:04:58	Epoch 3 testing start
2022-04-12 00:04:58	Valid Loss: 0.1974049
2022-04-12 00:05:03	Epoch: 3	Catergory: transistor	Pixel-AUC: 0.729540	Image-AUC: 0.635417
2022-04-12 00:05:03	Epoch 3 testing end, total 4.52s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:03	Epoch 4[32/170]: loss:1.00056, lr:0.40000, batch time:0.0309, data time:0.1986
2022-04-12 00:05:03	Epoch 4[96/170]: loss:0.96248, lr:0.40000, batch time:0.0528, data time:0.1858
2022-04-12 00:05:04	Epoch 4[160/170]: loss:0.96638, lr:0.40000, batch time:0.0514, data time:0.1888
2022-04-12 00:05:04	Epoch 4 training ends, total 1.27s
2022-04-12 00:05:04	Epoch 4 testing start
2022-04-12 00:05:04	Valid Loss: 0.0906563
2022-04-12 00:05:08	Epoch: 4	Catergory: transistor	Pixel-AUC: 0.728228	Image-AUC: 0.717083
2022-04-12 00:05:08	Epoch 4 testing end, total 4.47s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:09	Epoch 5[32/170]: loss:0.91736, lr:0.40000, batch time:0.0725, data time:0.1989
2022-04-12 00:05:09	Epoch 5[96/170]: loss:0.89517, lr:0.40000, batch time:0.0555, data time:0.1888
2022-04-12 00:05:10	Epoch 5[160/170]: loss:0.87203, lr:0.40000, batch time:0.0564, data time:0.1879
2022-04-12 00:05:10	Epoch 5 training ends, total 1.30s
2022-04-12 00:05:10	Epoch 5 testing start
2022-04-12 00:05:10	Valid Loss: 0.0637413
2022-04-12 00:05:14	Epoch: 5	Catergory: transistor	Pixel-AUC: 0.736897	Image-AUC: 0.712500
2022-04-12 00:05:14	Epoch 5 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:14	Epoch 6[32/170]: loss:0.85177, lr:0.40000, batch time:0.0701, data time:0.2002
2022-04-12 00:05:15	Epoch 6[96/170]: loss:0.82753, lr:0.40000, batch time:0.0545, data time:0.1855
2022-04-12 00:05:15	Epoch 6[160/170]: loss:0.78881, lr:0.40000, batch time:0.0537, data time:0.1858
2022-04-12 00:05:15	Epoch 6 training ends, total 1.29s
2022-04-12 00:05:15	Epoch 6 testing start
2022-04-12 00:05:16	Valid Loss: 0.0427297
2022-04-12 00:05:20	Epoch: 6	Catergory: transistor	Pixel-AUC: 0.735464	Image-AUC: 0.725417
2022-04-12 00:05:20	Epoch 6 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:20	Epoch 7[32/170]: loss:0.78883, lr:0.40000, batch time:0.0514, data time:0.1988
2022-04-12 00:05:20	Epoch 7[96/170]: loss:0.76486, lr:0.40000, batch time:0.0567, data time:0.1883
2022-04-12 00:05:21	Epoch 7[160/170]: loss:0.74030, lr:0.40000, batch time:0.0536, data time:0.1831
2022-04-12 00:05:21	Epoch 7 training ends, total 1.29s
2022-04-12 00:05:21	Epoch 7 testing start
2022-04-12 00:05:21	Valid Loss: 0.0346458
2022-04-12 00:05:25	Epoch: 7	Catergory: transistor	Pixel-AUC: 0.735830	Image-AUC: 0.741667
2022-04-12 00:05:25	Epoch 7 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:26	Epoch 8[32/170]: loss:0.72560, lr:0.40000, batch time:0.0323, data time:0.2011
2022-04-12 00:05:26	Epoch 8[96/170]: loss:0.72220, lr:0.40000, batch time:0.0536, data time:0.1908
2022-04-12 00:05:27	Epoch 8[160/170]: loss:0.71046, lr:0.40000, batch time:0.0565, data time:0.1860
2022-04-12 00:05:27	Epoch 8 training ends, total 1.30s
2022-04-12 00:05:27	Epoch 8 testing start
2022-04-12 00:05:27	Valid Loss: 0.0288862
2022-04-12 00:05:31	Epoch: 8	Catergory: transistor	Pixel-AUC: 0.739153	Image-AUC: 0.745833
2022-04-12 00:05:31	Epoch 8 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:31	Epoch 9[32/170]: loss:0.70140, lr:0.40000, batch time:0.0317, data time:0.2022
2022-04-12 00:05:32	Epoch 9[96/170]: loss:0.66558, lr:0.40000, batch time:0.0532, data time:0.1904
2022-04-12 00:05:32	Epoch 9[160/170]: loss:0.67396, lr:0.40000, batch time:0.0537, data time:0.2100
2022-04-12 00:05:32	Epoch 9 training ends, total 1.30s
2022-04-12 00:05:32	Epoch 9 testing start
2022-04-12 00:05:33	Valid Loss: 0.0257111
2022-04-12 00:05:37	Epoch: 9	Catergory: transistor	Pixel-AUC: 0.742696	Image-AUC: 0.759583
2022-04-12 00:05:37	Epoch 9 testing end, total 4.41s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:37	Epoch 10[32/170]: loss:0.65821, lr:0.40000, batch time:0.0313, data time:0.2010
2022-04-12 00:05:38	Epoch 10[96/170]: loss:0.65925, lr:0.40000, batch time:0.0554, data time:0.1860
2022-04-12 00:05:38	Epoch 10[160/170]: loss:0.64964, lr:0.40000, batch time:0.0505, data time:0.1858
2022-04-12 00:05:38	Epoch 10 training ends, total 1.28s
2022-04-12 00:05:38	Epoch 10 testing start
2022-04-12 00:05:38	Valid Loss: 0.0220765
2022-04-12 00:05:43	Epoch: 10	Catergory: transistor	Pixel-AUC: 0.745041	Image-AUC: 0.761667
2022-04-12 00:05:43	Epoch 10 testing end, total 4.45s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:43	Epoch 11[32/170]: loss:0.63312, lr:0.40000, batch time:0.0310, data time:0.2038
2022-04-12 00:05:43	Epoch 11[96/170]: loss:0.62842, lr:0.40000, batch time:0.0577, data time:0.1891
2022-04-12 00:05:44	Epoch 11[160/170]: loss:0.61133, lr:0.40000, batch time:0.0512, data time:0.1847
2022-04-12 00:05:44	Epoch 11 training ends, total 1.29s
2022-04-12 00:05:44	Epoch 11 testing start
2022-04-12 00:05:44	Valid Loss: 0.0196404
2022-04-12 00:05:48	Epoch: 11	Catergory: transistor	Pixel-AUC: 0.747236	Image-AUC: 0.781667
2022-04-12 00:05:48	Epoch 11 testing end, total 4.47s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:49	Epoch 12[32/170]: loss:0.61173, lr:0.40000, batch time:0.0311, data time:0.2024
2022-04-12 00:05:49	Epoch 12[96/170]: loss:0.59109, lr:0.40000, batch time:0.0313, data time:0.1893
2022-04-12 00:05:50	Epoch 12[160/170]: loss:0.58652, lr:0.40000, batch time:0.0515, data time:0.2079
2022-04-12 00:05:50	Epoch 12 training ends, total 1.29s
2022-04-12 00:05:50	Epoch 12 testing start
2022-04-12 00:05:50	Valid Loss: 0.0175796
2022-04-12 00:05:54	Epoch: 12	Catergory: transistor	Pixel-AUC: 0.749892	Image-AUC: 0.782083
2022-04-12 00:05:54	Epoch 12 testing end, total 4.44s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:05:54	Epoch 13[32/170]: loss:0.58802, lr:0.40000, batch time:0.0328, data time:0.2034
2022-04-12 00:05:55	Epoch 13[96/170]: loss:0.57700, lr:0.40000, batch time:0.0575, data time:0.1806
2022-04-12 00:05:55	Epoch 13[160/170]: loss:0.56922, lr:0.40000, batch time:0.0564, data time:0.1879
2022-04-12 00:05:55	Epoch 13 training ends, total 1.32s
2022-04-12 00:05:55	Epoch 13 testing start
2022-04-12 00:05:56	Valid Loss: 0.0157571
2022-04-12 00:06:00	Epoch: 13	Catergory: transistor	Pixel-AUC: 0.753382	Image-AUC: 0.775417
2022-04-12 00:06:00	Epoch 13 testing end, total 4.44s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:00	Epoch 14[32/170]: loss:0.57221, lr:0.40000, batch time:0.0315, data time:0.2048
2022-04-12 00:06:01	Epoch 14[96/170]: loss:0.56636, lr:0.40000, batch time:0.0522, data time:0.1887
2022-04-12 00:06:01	Epoch 14[160/170]: loss:0.55220, lr:0.40000, batch time:0.0514, data time:0.1886
2022-04-12 00:06:01	Epoch 14 training ends, total 1.30s
2022-04-12 00:06:01	Epoch 14 testing start
2022-04-12 00:06:01	Valid Loss: 0.0148243
2022-04-12 00:06:06	Epoch: 14	Catergory: transistor	Pixel-AUC: 0.758339	Image-AUC: 0.822500
2022-04-12 00:06:06	Epoch 14 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:06	Epoch 15[32/170]: loss:0.55646, lr:0.40000, batch time:0.0506, data time:0.2023
2022-04-12 00:06:06	Epoch 15[96/170]: loss:0.54560, lr:0.40000, batch time:0.0510, data time:0.1998
2022-04-12 00:06:07	Epoch 15[160/170]: loss:0.53243, lr:0.40000, batch time:0.0521, data time:0.1884
2022-04-12 00:06:07	Epoch 15 training ends, total 1.30s
2022-04-12 00:06:07	Epoch 15 testing start
2022-04-12 00:06:07	Valid Loss: 0.0126928
2022-04-12 00:06:11	Epoch: 15	Catergory: transistor	Pixel-AUC: 0.759324	Image-AUC: 0.800000
2022-04-12 00:06:11	Epoch 15 testing end, total 4.45s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:12	Epoch 16[32/170]: loss:0.53502, lr:0.40000, batch time:0.0312, data time:0.1987
2022-04-12 00:06:12	Epoch 16[96/170]: loss:0.53051, lr:0.40000, batch time:0.0531, data time:0.1872
2022-04-12 00:06:13	Epoch 16[160/170]: loss:0.51831, lr:0.40000, batch time:0.0529, data time:0.1857
2022-04-12 00:06:13	Epoch 16 training ends, total 1.27s
2022-04-12 00:06:13	Epoch 16 testing start
2022-04-12 00:06:13	Valid Loss: 0.0114362
2022-04-12 00:06:17	Epoch: 16	Catergory: transistor	Pixel-AUC: 0.761675	Image-AUC: 0.810000
2022-04-12 00:06:17	Epoch 16 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:17	Epoch 17[32/170]: loss:0.51584, lr:0.40000, batch time:0.0502, data time:0.2007
2022-04-12 00:06:18	Epoch 17[96/170]: loss:0.49621, lr:0.40000, batch time:0.0519, data time:0.1840
2022-04-12 00:06:18	Epoch 17[160/170]: loss:0.50512, lr:0.40000, batch time:0.0534, data time:0.1835
2022-04-12 00:06:18	Epoch 17 training ends, total 1.28s
2022-04-12 00:06:18	Epoch 17 testing start
2022-04-12 00:06:19	Valid Loss: 0.0105893
2022-04-12 00:06:23	Epoch: 17	Catergory: transistor	Pixel-AUC: 0.765059	Image-AUC: 0.825417
2022-04-12 00:06:23	Epoch 17 testing end, total 4.41s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:23	Epoch 18[32/170]: loss:0.49906, lr:0.40000, batch time:0.0308, data time:0.2019
2022-04-12 00:06:23	Epoch 18[96/170]: loss:0.49439, lr:0.40000, batch time:0.0556, data time:0.1860
2022-04-12 00:06:24	Epoch 18[160/170]: loss:0.48904, lr:0.40000, batch time:0.0541, data time:0.1797
2022-04-12 00:06:24	Epoch 18 training ends, total 1.28s
2022-04-12 00:06:24	Epoch 18 testing start
2022-04-12 00:06:24	Valid Loss: 0.0115702
2022-04-12 00:06:28	Epoch: 18	Catergory: transistor	Pixel-AUC: 0.764050	Image-AUC: 0.880417
2022-04-12 00:06:28	Epoch 18 testing end, total 4.23s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:28	Epoch 19[32/170]: loss:0.48731, lr:0.40000, batch time:0.0488, data time:0.2002
2022-04-12 00:06:29	Epoch 19[96/170]: loss:0.48734, lr:0.40000, batch time:0.0505, data time:0.1832
2022-04-12 00:06:29	Epoch 19[160/170]: loss:0.47213, lr:0.40000, batch time:0.0511, data time:0.1888
2022-04-12 00:06:29	Epoch 19 training ends, total 1.29s
2022-04-12 00:06:29	Epoch 19 testing start
2022-04-12 00:06:30	Valid Loss: 0.0093918
2022-04-12 00:06:34	Epoch: 19	Catergory: transistor	Pixel-AUC: 0.769160	Image-AUC: 0.869583
2022-04-12 00:06:34	Epoch 19 testing end, total 4.37s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:34	Epoch 20[32/170]: loss:0.47462, lr:0.40000, batch time:0.0309, data time:0.2055
2022-04-12 00:06:35	Epoch 20[96/170]: loss:0.46973, lr:0.40000, batch time:0.0506, data time:0.1882
2022-04-12 00:06:35	Epoch 20[160/170]: loss:0.46613, lr:0.40000, batch time:0.0532, data time:0.1891
2022-04-12 00:06:35	Epoch 20 training ends, total 1.29s
2022-04-12 00:06:35	Epoch 20 testing start
2022-04-12 00:06:35	Valid Loss: 0.0086251
2022-04-12 00:06:40	Epoch: 20	Catergory: transistor	Pixel-AUC: 0.770703	Image-AUC: 0.867500
2022-04-12 00:06:40	Epoch 20 testing end, total 4.37s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:40	Epoch 21[32/170]: loss:0.46239, lr:0.40000, batch time:0.0336, data time:0.2008
2022-04-12 00:06:40	Epoch 21[96/170]: loss:0.45617, lr:0.40000, batch time:0.0544, data time:0.1895
2022-04-12 00:06:41	Epoch 21[160/170]: loss:0.46510, lr:0.40000, batch time:0.0580, data time:0.1846
2022-04-12 00:06:41	Epoch 21 training ends, total 1.30s
2022-04-12 00:06:41	Epoch 21 testing start
2022-04-12 00:06:41	Valid Loss: 0.0080600
2022-04-12 00:06:45	Epoch: 21	Catergory: transistor	Pixel-AUC: 0.773816	Image-AUC: 0.873750
2022-04-12 00:06:45	Epoch 21 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:45	Epoch 22[32/170]: loss:0.45760, lr:0.40000, batch time:0.0492, data time:0.2007
2022-04-12 00:06:46	Epoch 22[96/170]: loss:0.45394, lr:0.40000, batch time:0.0520, data time:0.1873
2022-04-12 00:06:46	Epoch 22[160/170]: loss:0.45047, lr:0.40000, batch time:0.0541, data time:0.1887
2022-04-12 00:06:47	Epoch 22 training ends, total 1.29s
2022-04-12 00:06:47	Epoch 22 testing start
2022-04-12 00:06:47	Valid Loss: 0.0186633
2022-04-12 00:06:51	Epoch: 22	Catergory: transistor	Pixel-AUC: 0.756206	Image-AUC: 0.634167
2022-04-12 00:06:51	Epoch 22 testing end, total 4.29s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:51	Epoch 23[32/170]: loss:0.49848, lr:0.40000, batch time:0.0312, data time:0.2003
2022-04-12 00:06:52	Epoch 23[96/170]: loss:0.48839, lr:0.40000, batch time:0.0523, data time:0.1878
2022-04-12 00:06:52	Epoch 23[160/170]: loss:0.46559, lr:0.40000, batch time:0.0521, data time:0.1843
2022-04-12 00:06:52	Epoch 23 training ends, total 1.28s
2022-04-12 00:06:52	Epoch 23 testing start
2022-04-12 00:06:52	Valid Loss: 0.0151914
2022-04-12 00:06:56	Epoch: 23	Catergory: transistor	Pixel-AUC: 0.765368	Image-AUC: 0.770000
2022-04-12 00:06:56	Epoch 23 testing end, total 4.25s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:06:57	Epoch 24[32/170]: loss:0.46174, lr:0.40000, batch time:0.0308, data time:0.2001
2022-04-12 00:06:57	Epoch 24[96/170]: loss:0.45799, lr:0.40000, batch time:0.0508, data time:0.1853
2022-04-12 00:06:58	Epoch 24[160/170]: loss:0.44220, lr:0.40000, batch time:0.0533, data time:0.1863
2022-04-12 00:06:58	Epoch 24 training ends, total 1.28s
2022-04-12 00:06:58	Epoch 24 testing start
2022-04-12 00:06:58	Valid Loss: 0.0106802
2022-04-12 00:07:02	Epoch: 24	Catergory: transistor	Pixel-AUC: 0.770114	Image-AUC: 0.873750
2022-04-12 00:07:02	Epoch 24 testing end, total 4.30s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:02	Epoch 25[32/170]: loss:0.45042, lr:0.40000, batch time:0.0313, data time:0.2002
2022-04-12 00:07:03	Epoch 25[96/170]: loss:0.44163, lr:0.40000, batch time:0.0516, data time:0.1892
2022-04-12 00:07:03	Epoch 25[160/170]: loss:0.43045, lr:0.40000, batch time:0.0496, data time:0.1845
2022-04-12 00:07:03	Epoch 25 training ends, total 1.28s
2022-04-12 00:07:03	Epoch 25 testing start
2022-04-12 00:07:04	Valid Loss: 0.0073706
2022-04-12 00:07:08	Epoch: 25	Catergory: transistor	Pixel-AUC: 0.777057	Image-AUC: 0.892083
2022-04-12 00:07:08	Epoch 25 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:08	Epoch 26[32/170]: loss:0.43270, lr:0.40000, batch time:0.0312, data time:0.2011
2022-04-12 00:07:08	Epoch 26[96/170]: loss:0.42359, lr:0.40000, batch time:0.0520, data time:0.1882
2022-04-12 00:07:09	Epoch 26[160/170]: loss:0.43738, lr:0.40000, batch time:0.0555, data time:0.1826
2022-04-12 00:07:09	Epoch 26 training ends, total 1.28s
2022-04-12 00:07:09	Epoch 26 testing start
2022-04-12 00:07:09	Valid Loss: 0.0068133
2022-04-12 00:07:13	Epoch: 26	Catergory: transistor	Pixel-AUC: 0.780096	Image-AUC: 0.893333
2022-04-12 00:07:13	Epoch 26 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:14	Epoch 27[32/170]: loss:0.44135, lr:0.40000, batch time:0.0667, data time:0.1999
2022-04-12 00:07:14	Epoch 27[96/170]: loss:0.42094, lr:0.40000, batch time:0.0312, data time:0.2087
2022-04-12 00:07:15	Epoch 27[160/170]: loss:0.41933, lr:0.40000, batch time:0.0523, data time:0.1888
2022-04-12 00:07:15	Epoch 27 training ends, total 1.28s
2022-04-12 00:07:15	Epoch 27 testing start
2022-04-12 00:07:15	Valid Loss: 0.0059824
2022-04-12 00:07:19	Epoch: 27	Catergory: transistor	Pixel-AUC: 0.779207	Image-AUC: 0.885833
2022-04-12 00:07:19	Epoch 27 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:19	Epoch 28[32/170]: loss:0.41714, lr:0.40000, batch time:0.0317, data time:0.1994
2022-04-12 00:07:20	Epoch 28[96/170]: loss:0.41830, lr:0.40000, batch time:0.0620, data time:0.1889
2022-04-12 00:07:20	Epoch 28[160/170]: loss:0.41080, lr:0.40000, batch time:0.0504, data time:0.1887
2022-04-12 00:07:20	Epoch 28 training ends, total 1.30s
2022-04-12 00:07:20	Epoch 28 testing start
2022-04-12 00:07:21	Valid Loss: 0.0058080
2022-04-12 00:07:25	Epoch: 28	Catergory: transistor	Pixel-AUC: 0.780603	Image-AUC: 0.895833
2022-04-12 00:07:25	Epoch 28 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:25	Epoch 29[32/170]: loss:0.40602, lr:0.40000, batch time:0.0336, data time:0.2010
2022-04-12 00:07:25	Epoch 29[96/170]: loss:0.40740, lr:0.40000, batch time:0.0320, data time:0.1903
2022-04-12 00:07:26	Epoch 29[160/170]: loss:0.41083, lr:0.40000, batch time:0.0547, data time:0.1889
2022-04-12 00:07:26	Epoch 29 training ends, total 1.30s
2022-04-12 00:07:26	Epoch 29 testing start
2022-04-12 00:07:26	Valid Loss: 0.0055535
2022-04-12 00:07:30	Epoch: 29	Catergory: transistor	Pixel-AUC: 0.783953	Image-AUC: 0.906667
2022-04-12 00:07:30	Epoch 29 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:31	Epoch 30[32/170]: loss:0.39791, lr:0.40000, batch time:0.0311, data time:0.1998
2022-04-12 00:07:31	Epoch 30[96/170]: loss:0.40374, lr:0.40000, batch time:0.0310, data time:0.1856
2022-04-12 00:07:32	Epoch 30[160/170]: loss:0.39882, lr:0.40000, batch time:0.0668, data time:0.1750
2022-04-12 00:07:32	Epoch 30 training ends, total 1.28s
2022-04-12 00:07:32	Epoch 30 testing start
2022-04-12 00:07:32	Valid Loss: 0.0054883
2022-04-12 00:07:36	Epoch: 30	Catergory: transistor	Pixel-AUC: 0.783191	Image-AUC: 0.895833
2022-04-12 00:07:36	Epoch 30 testing end, total 4.48s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:36	Epoch 31[32/170]: loss:0.39556, lr:0.40000, batch time:0.0664, data time:0.2021
2022-04-12 00:07:37	Epoch 31[96/170]: loss:0.39715, lr:0.40000, batch time:0.0488, data time:0.1911
2022-04-12 00:07:37	Epoch 31[160/170]: loss:0.39068, lr:0.40000, batch time:0.0490, data time:0.1899
2022-04-12 00:07:37	Epoch 31 training ends, total 1.28s
2022-04-12 00:07:37	Epoch 31 testing start
2022-04-12 00:07:38	Valid Loss: 0.0050177
2022-04-12 00:07:42	Epoch: 31	Catergory: transistor	Pixel-AUC: 0.786548	Image-AUC: 0.899583
2022-04-12 00:07:42	Epoch 31 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:42	Epoch 32[32/170]: loss:0.38839, lr:0.40000, batch time:0.0481, data time:0.2010
2022-04-12 00:07:43	Epoch 32[96/170]: loss:0.39226, lr:0.40000, batch time:0.0528, data time:0.1856
2022-04-12 00:07:43	Epoch 32[160/170]: loss:0.38780, lr:0.40000, batch time:0.0521, data time:0.1895
2022-04-12 00:07:43	Epoch 32 training ends, total 1.28s
2022-04-12 00:07:43	Epoch 32 testing start
2022-04-12 00:07:43	Valid Loss: 0.0049427
2022-04-12 00:07:48	Epoch: 32	Catergory: transistor	Pixel-AUC: 0.786015	Image-AUC: 0.899583
2022-04-12 00:07:48	Epoch 32 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:48	Epoch 33[32/170]: loss:0.39411, lr:0.40000, batch time:0.0311, data time:0.2001
2022-04-12 00:07:48	Epoch 33[96/170]: loss:0.38112, lr:0.40000, batch time:0.0541, data time:0.1850
2022-04-12 00:07:49	Epoch 33[160/170]: loss:0.38503, lr:0.40000, batch time:0.0527, data time:0.1832
2022-04-12 00:07:49	Epoch 33 training ends, total 1.27s
2022-04-12 00:07:49	Epoch 33 testing start
2022-04-12 00:07:49	Valid Loss: 0.0045826
2022-04-12 00:07:53	Epoch: 33	Catergory: transistor	Pixel-AUC: 0.788777	Image-AUC: 0.904583
2022-04-12 00:07:53	Epoch 33 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:54	Epoch 34[32/170]: loss:0.37380, lr:0.40000, batch time:0.0311, data time:0.2000
2022-04-12 00:07:54	Epoch 34[96/170]: loss:0.38934, lr:0.40000, batch time:0.0539, data time:0.1836
2022-04-12 00:07:54	Epoch 34[160/170]: loss:0.38701, lr:0.40000, batch time:0.0528, data time:0.1846
2022-04-12 00:07:55	Epoch 34 training ends, total 1.28s
2022-04-12 00:07:55	Epoch 34 testing start
2022-04-12 00:07:55	Valid Loss: 0.0045132
2022-04-12 00:07:59	Epoch: 34	Catergory: transistor	Pixel-AUC: 0.787978	Image-AUC: 0.909167
2022-04-12 00:07:59	Epoch 34 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:07:59	Epoch 35[32/170]: loss:0.37902, lr:0.40000, batch time:0.0311, data time:0.2003
2022-04-12 00:08:00	Epoch 35[96/170]: loss:0.38372, lr:0.40000, batch time:0.0670, data time:0.1884
2022-04-12 00:08:00	Epoch 35[160/170]: loss:0.37265, lr:0.40000, batch time:0.0527, data time:0.1878
2022-04-12 00:08:00	Epoch 35 training ends, total 1.28s
2022-04-12 00:08:00	Epoch 35 testing start
2022-04-12 00:08:01	Valid Loss: 0.0045904
2022-04-12 00:08:05	Epoch: 35	Catergory: transistor	Pixel-AUC: 0.790033	Image-AUC: 0.909583
2022-04-12 00:08:05	Epoch 35 testing end, total 4.33s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:05	Epoch 36[32/170]: loss:0.37113, lr:0.40000, batch time:0.0491, data time:0.2016
2022-04-12 00:08:05	Epoch 36[96/170]: loss:0.37072, lr:0.40000, batch time:0.0523, data time:0.1909
2022-04-12 00:08:06	Epoch 36[160/170]: loss:0.37783, lr:0.40000, batch time:0.0504, data time:0.1884
2022-04-12 00:08:06	Epoch 36 training ends, total 1.30s
2022-04-12 00:08:06	Epoch 36 testing start
2022-04-12 00:08:06	Valid Loss: 0.0042349
2022-04-12 00:08:10	Epoch: 36	Catergory: transistor	Pixel-AUC: 0.788774	Image-AUC: 0.902083
2022-04-12 00:08:10	Epoch 36 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:11	Epoch 37[32/170]: loss:0.36158, lr:0.40000, batch time:0.0754, data time:0.2009
2022-04-12 00:08:11	Epoch 37[96/170]: loss:0.37476, lr:0.40000, batch time:0.0800, data time:0.1781
2022-04-12 00:08:12	Epoch 37[160/170]: loss:0.37472, lr:0.40000, batch time:0.0694, data time:0.2103
2022-04-12 00:08:12	Epoch 37 training ends, total 1.33s
2022-04-12 00:08:12	Epoch 37 testing start
2022-04-12 00:08:12	Valid Loss: 0.0042501
2022-04-12 00:08:16	Epoch: 37	Catergory: transistor	Pixel-AUC: 0.791318	Image-AUC: 0.917083
2022-04-12 00:08:16	Epoch 37 testing end, total 4.34s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:16	Epoch 38[32/170]: loss:0.36673, lr:0.40000, batch time:0.0314, data time:0.2032
2022-04-12 00:08:17	Epoch 38[96/170]: loss:0.36038, lr:0.40000, batch time:0.0318, data time:0.2119
2022-04-12 00:08:17	Epoch 38[160/170]: loss:0.35821, lr:0.40000, batch time:0.0483, data time:0.1881
2022-04-12 00:08:17	Epoch 38 training ends, total 1.30s
2022-04-12 00:08:17	Epoch 38 testing start
2022-04-12 00:08:18	Valid Loss: 0.0039232
2022-04-12 00:08:22	Epoch: 38	Catergory: transistor	Pixel-AUC: 0.790188	Image-AUC: 0.909583
2022-04-12 00:08:22	Epoch 38 testing end, total 4.52s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:22	Epoch 39[32/170]: loss:0.36293, lr:0.40000, batch time:0.0310, data time:0.1996
2022-04-12 00:08:23	Epoch 39[96/170]: loss:0.36754, lr:0.40000, batch time:0.0498, data time:0.1843
2022-04-12 00:08:23	Epoch 39[160/170]: loss:0.35997, lr:0.40000, batch time:0.0511, data time:0.1862
2022-04-12 00:08:23	Epoch 39 training ends, total 1.27s
2022-04-12 00:08:23	Epoch 39 testing start
2022-04-12 00:08:23	Valid Loss: 0.0041197
2022-04-12 00:08:27	Epoch: 39	Catergory: transistor	Pixel-AUC: 0.793292	Image-AUC: 0.917500
2022-04-12 00:08:27	Epoch 39 testing end, total 4.25s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:28	Epoch 40[32/170]: loss:0.35701, lr:0.40000, batch time:0.0314, data time:0.1993
2022-04-12 00:08:28	Epoch 40[96/170]: loss:0.35955, lr:0.40000, batch time:0.0500, data time:0.1837
2022-04-12 00:08:29	Epoch 40[160/170]: loss:0.35243, lr:0.40000, batch time:0.0664, data time:0.1727
2022-04-12 00:08:29	Epoch 40 training ends, total 1.27s
2022-04-12 00:08:29	Epoch 40 testing start
2022-04-12 00:08:29	Valid Loss: 0.0040315
2022-04-12 00:08:33	Epoch: 40	Catergory: transistor	Pixel-AUC: 0.791719	Image-AUC: 0.913750
2022-04-12 00:08:33	Epoch 40 testing end, total 4.32s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:33	Epoch 41[32/170]: loss:0.34883, lr:0.40000, batch time:0.0491, data time:0.2034
2022-04-12 00:08:34	Epoch 41[96/170]: loss:0.34917, lr:0.40000, batch time:0.0520, data time:0.1866
2022-04-12 00:08:34	Epoch 41[160/170]: loss:0.34749, lr:0.40000, batch time:0.0528, data time:0.1823
2022-04-12 00:08:34	Epoch 41 training ends, total 1.28s
2022-04-12 00:08:34	Epoch 41 testing start
2022-04-12 00:08:35	Valid Loss: 0.0035396
2022-04-12 00:08:39	Epoch: 41	Catergory: transistor	Pixel-AUC: 0.795211	Image-AUC: 0.919583
2022-04-12 00:08:39	Epoch 41 testing end, total 4.44s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:39	Epoch 42[32/170]: loss:0.34701, lr:0.40000, batch time:0.0309, data time:0.2017
2022-04-12 00:08:39	Epoch 42[96/170]: loss:0.35046, lr:0.40000, batch time:0.0310, data time:0.2066
2022-04-12 00:08:40	Epoch 42[160/170]: loss:0.34924, lr:0.40000, batch time:0.0316, data time:0.1877
2022-04-12 00:08:40	Epoch 42 training ends, total 1.29s
2022-04-12 00:08:40	Epoch 42 testing start
2022-04-12 00:08:40	Valid Loss: 0.0033898
2022-04-12 00:08:44	Epoch: 42	Catergory: transistor	Pixel-AUC: 0.793193	Image-AUC: 0.919167
2022-04-12 00:08:44	Epoch 42 testing end, total 4.44s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:45	Epoch 43[32/170]: loss:0.34727, lr:0.40000, batch time:0.0311, data time:0.2001
2022-04-12 00:08:45	Epoch 43[96/170]: loss:0.34462, lr:0.40000, batch time:0.0530, data time:0.1879
2022-04-12 00:08:46	Epoch 43[160/170]: loss:0.34339, lr:0.40000, batch time:0.0525, data time:0.1807
2022-04-12 00:08:46	Epoch 43 training ends, total 1.28s
2022-04-12 00:08:46	Epoch 43 testing start
2022-04-12 00:08:46	Valid Loss: 0.0033028
2022-04-12 00:08:50	Epoch: 43	Catergory: transistor	Pixel-AUC: 0.795590	Image-AUC: 0.920833
2022-04-12 00:08:50	Epoch 43 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:50	Epoch 44[32/170]: loss:0.34463, lr:0.40000, batch time:0.0493, data time:0.2062
2022-04-12 00:08:51	Epoch 44[96/170]: loss:0.32925, lr:0.40000, batch time:0.0516, data time:0.1866
2022-04-12 00:08:51	Epoch 44[160/170]: loss:0.34285, lr:0.40000, batch time:0.0507, data time:0.1883
2022-04-12 00:08:51	Epoch 44 training ends, total 1.29s
2022-04-12 00:08:51	Epoch 44 testing start
2022-04-12 00:08:52	Valid Loss: 0.0038591
2022-04-12 00:08:56	Epoch: 44	Catergory: transistor	Pixel-AUC: 0.795915	Image-AUC: 0.930000
2022-04-12 00:08:56	Epoch 44 testing end, total 4.29s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:08:56	Epoch 45[32/170]: loss:0.34804, lr:0.40000, batch time:0.0328, data time:0.2012
2022-04-12 00:08:56	Epoch 45[96/170]: loss:0.33568, lr:0.40000, batch time:0.0563, data time:0.1873
2022-04-12 00:08:57	Epoch 45[160/170]: loss:0.34366, lr:0.40000, batch time:0.0526, data time:0.1870
2022-04-12 00:08:57	Epoch 45 training ends, total 1.30s
2022-04-12 00:08:57	Epoch 45 testing start
2022-04-12 00:08:57	Valid Loss: 0.0032335
2022-04-12 00:09:01	Epoch: 45	Catergory: transistor	Pixel-AUC: 0.796932	Image-AUC: 0.922083
2022-04-12 00:09:01	Epoch 45 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:02	Epoch 46[32/170]: loss:0.33891, lr:0.40000, batch time:0.0310, data time:0.1998
2022-04-12 00:09:02	Epoch 46[96/170]: loss:0.34046, lr:0.40000, batch time:0.0520, data time:0.1843
2022-04-12 00:09:03	Epoch 46[160/170]: loss:0.32930, lr:0.40000, batch time:0.0529, data time:0.1878
2022-04-12 00:09:03	Epoch 46 training ends, total 1.27s
2022-04-12 00:09:03	Epoch 46 testing start
2022-04-12 00:09:03	Valid Loss: 0.0031984
2022-04-12 00:09:07	Epoch: 46	Catergory: transistor	Pixel-AUC: 0.797706	Image-AUC: 0.923750
2022-04-12 00:09:07	Epoch 46 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:07	Epoch 47[32/170]: loss:0.33237, lr:0.40000, batch time:0.0493, data time:0.2009
2022-04-12 00:09:08	Epoch 47[96/170]: loss:0.34195, lr:0.40000, batch time:0.0528, data time:0.1873
2022-04-12 00:09:08	Epoch 47[160/170]: loss:0.32381, lr:0.40000, batch time:0.0505, data time:0.1851
2022-04-12 00:09:08	Epoch 47 training ends, total 1.28s
2022-04-12 00:09:08	Epoch 47 testing start
2022-04-12 00:09:09	Valid Loss: 0.0030037
2022-04-12 00:09:13	Epoch: 47	Catergory: transistor	Pixel-AUC: 0.797362	Image-AUC: 0.921667
2022-04-12 00:09:13	Epoch 47 testing end, total 4.49s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:13	Epoch 48[32/170]: loss:0.33107, lr:0.40000, batch time:0.0307, data time:0.1995
2022-04-12 00:09:14	Epoch 48[96/170]: loss:0.32582, lr:0.40000, batch time:0.0500, data time:0.1848
2022-04-12 00:09:14	Epoch 48[160/170]: loss:0.32613, lr:0.40000, batch time:0.0494, data time:0.2072
2022-04-12 00:09:14	Epoch 48 training ends, total 1.27s
2022-04-12 00:09:14	Epoch 48 testing start
2022-04-12 00:09:14	Valid Loss: 0.0028793
2022-04-12 00:09:18	Epoch: 48	Catergory: transistor	Pixel-AUC: 0.797964	Image-AUC: 0.921667
2022-04-12 00:09:18	Epoch 48 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:19	Epoch 49[32/170]: loss:0.31243, lr:0.40000, batch time:0.0309, data time:0.2002
2022-04-12 00:09:19	Epoch 49[96/170]: loss:0.33165, lr:0.40000, batch time:0.0512, data time:0.1840
2022-04-12 00:09:20	Epoch 49[160/170]: loss:0.32095, lr:0.40000, batch time:0.0541, data time:0.1843
2022-04-12 00:09:20	Epoch 49 training ends, total 1.27s
2022-04-12 00:09:20	Epoch 49 testing start
2022-04-12 00:09:20	Valid Loss: 0.0029040
2022-04-12 00:09:24	Epoch: 49	Catergory: transistor	Pixel-AUC: 0.799043	Image-AUC: 0.926667
2022-04-12 00:09:24	Epoch 49 testing end, total 4.25s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:24	Epoch 50[32/170]: loss:0.31951, lr:0.40000, batch time:0.0481, data time:0.2005
2022-04-12 00:09:25	Epoch 50[96/170]: loss:0.31970, lr:0.40000, batch time:0.0507, data time:0.1871
2022-04-12 00:09:25	Epoch 50[160/170]: loss:0.35593, lr:0.40000, batch time:0.0503, data time:0.1855
2022-04-12 00:09:25	Epoch 50 training ends, total 1.28s
2022-04-12 00:09:25	Epoch 50 testing start
2022-04-12 00:09:26	Valid Loss: 0.0040578
2022-04-12 00:09:30	Epoch: 50	Catergory: transistor	Pixel-AUC: 0.795671	Image-AUC: 0.935833
2022-04-12 00:09:30	Epoch 50 testing end, total 4.24s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:30	Epoch 51[32/170]: loss:0.35039, lr:0.40000, batch time:0.0499, data time:0.2005
2022-04-12 00:09:30	Epoch 51[96/170]: loss:0.32230, lr:0.40000, batch time:0.0539, data time:0.1862
2022-04-12 00:09:31	Epoch 51[160/170]: loss:0.32903, lr:0.40000, batch time:0.0538, data time:0.1708
2022-04-12 00:09:31	Epoch 51 training ends, total 1.28s
2022-04-12 00:09:31	Epoch 51 testing start
2022-04-12 00:09:31	Valid Loss: 0.0037106
2022-04-12 00:09:35	Epoch: 51	Catergory: transistor	Pixel-AUC: 0.799773	Image-AUC: 0.940000
2022-04-12 00:09:35	Epoch 51 testing end, total 4.32s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:35	Epoch 52[32/170]: loss:0.32267, lr:0.40000, batch time:0.0312, data time:0.2006
2022-04-12 00:09:36	Epoch 52[96/170]: loss:0.32749, lr:0.40000, batch time:0.0541, data time:0.1867
2022-04-12 00:09:36	Epoch 52[160/170]: loss:0.32233, lr:0.40000, batch time:0.0515, data time:0.1877
2022-04-12 00:09:36	Epoch 52 training ends, total 1.28s
2022-04-12 00:09:36	Epoch 52 testing start
2022-04-12 00:09:37	Valid Loss: 0.0032520
2022-04-12 00:09:41	Epoch: 52	Catergory: transistor	Pixel-AUC: 0.796990	Image-AUC: 0.933750
2022-04-12 00:09:41	Epoch 52 testing end, total 4.28s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:41	Epoch 53[32/170]: loss:0.31690, lr:0.40000, batch time:0.0331, data time:0.2010
2022-04-12 00:09:41	Epoch 53[96/170]: loss:0.31449, lr:0.40000, batch time:0.0529, data time:0.1904
2022-04-12 00:09:42	Epoch 53[160/170]: loss:0.32437, lr:0.40000, batch time:0.0511, data time:0.1856
2022-04-12 00:09:42	Epoch 53 training ends, total 1.30s
2022-04-12 00:09:42	Epoch 53 testing start
2022-04-12 00:09:42	Valid Loss: 0.0026862
2022-04-12 00:09:46	Epoch: 53	Catergory: transistor	Pixel-AUC: 0.801039	Image-AUC: 0.932500
2022-04-12 00:09:46	Epoch 53 testing end, total 4.49s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:47	Epoch 54[32/170]: loss:0.32304, lr:0.40000, batch time:0.0699, data time:0.2016
2022-04-12 00:09:47	Epoch 54[96/170]: loss:0.31288, lr:0.40000, batch time:0.0524, data time:0.1873
2022-04-12 00:09:48	Epoch 54[160/170]: loss:0.31794, lr:0.40000, batch time:0.0539, data time:0.1887
2022-04-12 00:09:48	Epoch 54 training ends, total 1.30s
2022-04-12 00:09:48	Epoch 54 testing start
2022-04-12 00:09:48	Valid Loss: 0.0025794
2022-04-12 00:09:52	Epoch: 54	Catergory: transistor	Pixel-AUC: 0.804622	Image-AUC: 0.933333
2022-04-12 00:09:52	Epoch 54 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:52	Epoch 55[32/170]: loss:0.30883, lr:0.40000, batch time:0.0335, data time:0.2019
2022-04-12 00:09:53	Epoch 55[96/170]: loss:0.31001, lr:0.40000, batch time:0.0505, data time:0.1874
2022-04-12 00:09:53	Epoch 55[160/170]: loss:0.31122, lr:0.40000, batch time:0.0314, data time:0.1882
2022-04-12 00:09:53	Epoch 55 training ends, total 1.29s
2022-04-12 00:09:53	Epoch 55 testing start
2022-04-12 00:09:54	Valid Loss: 0.0025599
2022-04-12 00:09:58	Epoch: 55	Catergory: transistor	Pixel-AUC: 0.802016	Image-AUC: 0.934583
2022-04-12 00:09:58	Epoch 55 testing end, total 4.49s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:09:58	Epoch 56[32/170]: loss:0.30641, lr:0.40000, batch time:0.0313, data time:0.2030
2022-04-12 00:09:59	Epoch 56[96/170]: loss:0.30210, lr:0.40000, batch time:0.0575, data time:0.1860
2022-04-12 00:09:59	Epoch 56[160/170]: loss:0.31609, lr:0.40000, batch time:0.0494, data time:0.1803
2022-04-12 00:09:59	Epoch 56 training ends, total 1.30s
2022-04-12 00:09:59	Epoch 56 testing start
2022-04-12 00:10:00	Valid Loss: 0.0024019
2022-04-12 00:10:04	Epoch: 56	Catergory: transistor	Pixel-AUC: 0.803280	Image-AUC: 0.939583
2022-04-12 00:10:04	Epoch 56 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:04	Epoch 57[32/170]: loss:0.30303, lr:0.40000, batch time:0.0509, data time:0.2008
2022-04-12 00:10:04	Epoch 57[96/170]: loss:0.30621, lr:0.40000, batch time:0.0501, data time:0.1884
2022-04-12 00:10:05	Epoch 57[160/170]: loss:0.30906, lr:0.40000, batch time:0.0530, data time:0.1856
2022-04-12 00:10:05	Epoch 57 training ends, total 1.28s
2022-04-12 00:10:05	Epoch 57 testing start
2022-04-12 00:10:05	Valid Loss: 0.0024873
2022-04-12 00:10:09	Epoch: 57	Catergory: transistor	Pixel-AUC: 0.802883	Image-AUC: 0.933750
2022-04-12 00:10:09	Epoch 57 testing end, total 4.27s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:09	Epoch 58[32/170]: loss:0.29672, lr:0.40000, batch time:0.0309, data time:0.2017
2022-04-12 00:10:10	Epoch 58[96/170]: loss:0.30400, lr:0.40000, batch time:0.0528, data time:0.1847
2022-04-12 00:10:10	Epoch 58[160/170]: loss:0.29688, lr:0.40000, batch time:0.0521, data time:0.1851
2022-04-12 00:10:10	Epoch 58 training ends, total 1.28s
2022-04-12 00:10:10	Epoch 58 testing start
2022-04-12 00:10:11	Valid Loss: 0.0025154
2022-04-12 00:10:15	Epoch: 58	Catergory: transistor	Pixel-AUC: 0.802458	Image-AUC: 0.935000
2022-04-12 00:10:15	Epoch 58 testing end, total 4.31s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:15	Epoch 59[32/170]: loss:0.29978, lr:0.40000, batch time:0.0485, data time:0.2047
2022-04-12 00:10:16	Epoch 59[96/170]: loss:0.30107, lr:0.40000, batch time:0.0513, data time:0.1903
2022-04-12 00:10:16	Epoch 59[160/170]: loss:0.29553, lr:0.40000, batch time:0.0530, data time:0.1854
2022-04-12 00:10:16	Epoch 59 training ends, total 1.30s
2022-04-12 00:10:16	Epoch 59 testing start
2022-04-12 00:10:16	Valid Loss: 0.0023065
2022-04-12 00:10:21	Epoch: 59	Catergory: transistor	Pixel-AUC: 0.802990	Image-AUC: 0.937083
2022-04-12 00:10:21	Epoch 59 testing end, total 4.45s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:21	Epoch 60[32/170]: loss:0.29921, lr:0.40000, batch time:0.0315, data time:0.2040
2022-04-12 00:10:21	Epoch 60[96/170]: loss:0.29700, lr:0.40000, batch time:0.0480, data time:0.1889
2022-04-12 00:10:22	Epoch 60[160/170]: loss:0.29442, lr:0.40000, batch time:0.0502, data time:0.1895
2022-04-12 00:10:22	Epoch 60 training ends, total 1.32s
2022-04-12 00:10:22	Epoch 60 testing start
2022-04-12 00:10:22	Valid Loss: 0.0023061
2022-04-12 00:10:26	Epoch: 60	Catergory: transistor	Pixel-AUC: 0.804575	Image-AUC: 0.935000
2022-04-12 00:10:26	Epoch 60 testing end, total 4.48s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:27	Epoch 61[32/170]: loss:0.29838, lr:0.40000, batch time:0.0726, data time:0.2005
2022-04-12 00:10:27	Epoch 61[96/170]: loss:0.28616, lr:0.40000, batch time:0.0548, data time:0.1902
2022-04-12 00:10:28	Epoch 61[160/170]: loss:0.29283, lr:0.40000, batch time:0.0534, data time:0.1873
2022-04-12 00:10:28	Epoch 61 training ends, total 1.30s
2022-04-12 00:10:28	Epoch 61 testing start
2022-04-12 00:10:28	Valid Loss: 0.0021611
2022-04-12 00:10:32	Epoch: 61	Catergory: transistor	Pixel-AUC: 0.805764	Image-AUC: 0.935000
2022-04-12 00:10:32	Epoch 61 testing end, total 4.48s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:32	Epoch 62[32/170]: loss:0.29025, lr:0.40000, batch time:0.0322, data time:0.2008
2022-04-12 00:10:33	Epoch 62[96/170]: loss:0.29331, lr:0.40000, batch time:0.0541, data time:0.1904
2022-04-12 00:10:33	Epoch 62[160/170]: loss:0.28913, lr:0.40000, batch time:0.0533, data time:0.1852
2022-04-12 00:10:33	Epoch 62 training ends, total 1.30s
2022-04-12 00:10:33	Epoch 62 testing start
2022-04-12 00:10:34	Valid Loss: 0.0021788
2022-04-12 00:10:38	Epoch: 62	Catergory: transistor	Pixel-AUC: 0.805415	Image-AUC: 0.937083
2022-04-12 00:10:38	Epoch 62 testing end, total 4.27s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:38	Epoch 63[32/170]: loss:0.29864, lr:0.40000, batch time:0.0312, data time:0.2000
2022-04-12 00:10:38	Epoch 63[96/170]: loss:0.28834, lr:0.40000, batch time:0.0537, data time:0.1866
2022-04-12 00:10:39	Epoch 63[160/170]: loss:0.28903, lr:0.40000, batch time:0.0506, data time:0.1925
2022-04-12 00:10:39	Epoch 63 training ends, total 1.28s
2022-04-12 00:10:39	Epoch 63 testing start
2022-04-12 00:10:39	Valid Loss: 0.0020078
2022-04-12 00:10:43	Epoch: 63	Catergory: transistor	Pixel-AUC: 0.806319	Image-AUC: 0.936667
2022-04-12 00:10:43	Epoch 63 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:44	Epoch 64[32/170]: loss:0.28110, lr:0.40000, batch time:0.0314, data time:0.1996
2022-04-12 00:10:44	Epoch 64[96/170]: loss:0.28855, lr:0.40000, batch time:0.0523, data time:0.1887
2022-04-12 00:10:45	Epoch 64[160/170]: loss:0.29475, lr:0.40000, batch time:0.0683, data time:0.1873
2022-04-12 00:10:45	Epoch 64 training ends, total 1.28s
2022-04-12 00:10:45	Epoch 64 testing start
2022-04-12 00:10:45	Valid Loss: 0.0019659
2022-04-12 00:10:49	Epoch: 64	Catergory: transistor	Pixel-AUC: 0.804908	Image-AUC: 0.936250
2022-04-12 00:10:49	Epoch 64 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:49	Epoch 65[32/170]: loss:0.28780, lr:0.40000, batch time:0.0309, data time:0.2003
2022-04-12 00:10:50	Epoch 65[96/170]: loss:0.28538, lr:0.40000, batch time:0.0530, data time:0.1867
2022-04-12 00:10:50	Epoch 65[160/170]: loss:0.28140, lr:0.40000, batch time:0.0517, data time:0.1870
2022-04-12 00:10:50	Epoch 65 training ends, total 1.28s
2022-04-12 00:10:50	Epoch 65 testing start
2022-04-12 00:10:51	Valid Loss: 0.0020099
2022-04-12 00:10:55	Epoch: 65	Catergory: transistor	Pixel-AUC: 0.806388	Image-AUC: 0.935833
2022-04-12 00:10:55	Epoch 65 testing end, total 4.31s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:10:55	Epoch 66[32/170]: loss:0.28544, lr:0.40000, batch time:0.0665, data time:0.1996
2022-04-12 00:10:55	Epoch 66[96/170]: loss:0.28551, lr:0.40000, batch time:0.0312, data time:0.1874
2022-04-12 00:10:56	Epoch 66[160/170]: loss:0.29050, lr:0.40000, batch time:0.0520, data time:0.1869
2022-04-12 00:10:56	Epoch 66 training ends, total 1.28s
2022-04-12 00:10:56	Epoch 66 testing start
2022-04-12 00:10:56	Valid Loss: 0.0019729
2022-04-12 00:11:00	Epoch: 66	Catergory: transistor	Pixel-AUC: 0.805035	Image-AUC: 0.939167
2022-04-12 00:11:00	Epoch 66 testing end, total 4.34s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:01	Epoch 67[32/170]: loss:0.28892, lr:0.40000, batch time:0.0685, data time:0.1997
2022-04-12 00:11:01	Epoch 67[96/170]: loss:0.27682, lr:0.40000, batch time:0.0310, data time:0.1704
2022-04-12 00:11:02	Epoch 67[160/170]: loss:0.28176, lr:0.40000, batch time:0.0317, data time:0.1773
2022-04-12 00:11:02	Epoch 67 training ends, total 1.28s
2022-04-12 00:11:02	Epoch 67 testing start
2022-04-12 00:11:02	Valid Loss: 0.0021334
2022-04-12 00:11:06	Epoch: 67	Catergory: transistor	Pixel-AUC: 0.805576	Image-AUC: 0.940417
2022-04-12 00:11:06	Epoch 67 testing end, total 4.32s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:06	Epoch 68[32/170]: loss:0.28085, lr:0.40000, batch time:0.0668, data time:0.2049
2022-04-12 00:11:07	Epoch 68[96/170]: loss:0.28584, lr:0.40000, batch time:0.0505, data time:0.1877
2022-04-12 00:11:07	Epoch 68[160/170]: loss:0.28406, lr:0.40000, batch time:0.0506, data time:0.1835
2022-04-12 00:11:07	Epoch 68 training ends, total 1.28s
2022-04-12 00:11:07	Epoch 68 testing start
2022-04-12 00:11:07	Valid Loss: 0.0022335
2022-04-12 00:11:12	Epoch: 68	Catergory: transistor	Pixel-AUC: 0.805500	Image-AUC: 0.945417
2022-04-12 00:11:12	Epoch 68 testing end, total 4.31s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:12	Epoch 69[32/170]: loss:0.28747, lr:0.40000, batch time:0.0729, data time:0.1998
2022-04-12 00:11:12	Epoch 69[96/170]: loss:0.28376, lr:0.40000, batch time:0.0534, data time:0.1901
2022-04-12 00:11:13	Epoch 69[160/170]: loss:0.28044, lr:0.40000, batch time:0.0536, data time:0.1861
2022-04-12 00:11:13	Epoch 69 training ends, total 1.30s
2022-04-12 00:11:13	Epoch 69 testing start
2022-04-12 00:11:13	Valid Loss: 0.0018343
2022-04-12 00:11:17	Epoch: 69	Catergory: transistor	Pixel-AUC: 0.806050	Image-AUC: 0.942917
2022-04-12 00:11:17	Epoch 69 testing end, total 4.45s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:18	Epoch 70[32/170]: loss:0.27885, lr:0.40000, batch time:0.0529, data time:0.2003
2022-04-12 00:11:18	Epoch 70[96/170]: loss:0.27568, lr:0.40000, batch time:0.0323, data time:0.1887
2022-04-12 00:11:18	Epoch 70[160/170]: loss:0.27902, lr:0.40000, batch time:0.0319, data time:0.2091
2022-04-12 00:11:19	Epoch 70 training ends, total 1.29s
2022-04-12 00:11:19	Epoch 70 testing start
2022-04-12 00:11:19	Valid Loss: 0.0019014
2022-04-12 00:11:23	Epoch: 70	Catergory: transistor	Pixel-AUC: 0.806738	Image-AUC: 0.941250
2022-04-12 00:11:23	Epoch 70 testing end, total 4.30s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:23	Epoch 71[32/170]: loss:0.27698, lr:0.40000, batch time:0.0312, data time:0.1989
2022-04-12 00:11:24	Epoch 71[96/170]: loss:0.27486, lr:0.40000, batch time:0.0530, data time:0.1868
2022-04-12 00:11:24	Epoch 71[160/170]: loss:0.27413, lr:0.40000, batch time:0.0520, data time:0.1846
2022-04-12 00:11:24	Epoch 71 training ends, total 1.27s
2022-04-12 00:11:24	Epoch 71 testing start
2022-04-12 00:11:24	Valid Loss: 0.0017937
2022-04-12 00:11:29	Epoch: 71	Catergory: transistor	Pixel-AUC: 0.808880	Image-AUC: 0.936667
2022-04-12 00:11:29	Epoch 71 testing end, total 4.53s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:29	Epoch 72[32/170]: loss:0.27486, lr:0.40000, batch time:0.0309, data time:0.2004
2022-04-12 00:11:29	Epoch 72[96/170]: loss:0.27676, lr:0.40000, batch time:0.0508, data time:0.1876
2022-04-12 00:11:30	Epoch 72[160/170]: loss:0.26810, lr:0.40000, batch time:0.0488, data time:0.1863
2022-04-12 00:11:30	Epoch 72 training ends, total 1.28s
2022-04-12 00:11:30	Epoch 72 testing start
2022-04-12 00:11:30	Valid Loss: 0.0017836
2022-04-12 00:11:34	Epoch: 72	Catergory: transistor	Pixel-AUC: 0.808536	Image-AUC: 0.941250
2022-04-12 00:11:34	Epoch 72 testing end, total 4.42s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:35	Epoch 73[32/170]: loss:0.27043, lr:0.40000, batch time:0.0480, data time:0.1997
2022-04-12 00:11:35	Epoch 73[96/170]: loss:0.27333, lr:0.40000, batch time:0.0521, data time:0.1849
2022-04-12 00:11:36	Epoch 73[160/170]: loss:0.27413, lr:0.40000, batch time:0.0500, data time:0.1817
2022-04-12 00:11:36	Epoch 73 training ends, total 1.28s
2022-04-12 00:11:36	Epoch 73 testing start
2022-04-12 00:11:36	Valid Loss: 0.0017172
2022-04-12 00:11:40	Epoch: 73	Catergory: transistor	Pixel-AUC: 0.809632	Image-AUC: 0.946250
2022-04-12 00:11:40	Epoch 73 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:40	Epoch 74[32/170]: loss:0.26695, lr:0.40000, batch time:0.0480, data time:0.1994
2022-04-12 00:11:41	Epoch 74[96/170]: loss:0.26970, lr:0.40000, batch time:0.0520, data time:0.1827
2022-04-12 00:11:41	Epoch 74[160/170]: loss:0.27013, lr:0.40000, batch time:0.0480, data time:0.1771
2022-04-12 00:11:41	Epoch 74 training ends, total 1.28s
2022-04-12 00:11:41	Epoch 74 testing start
2022-04-12 00:11:42	Valid Loss: 0.0016041
2022-04-12 00:11:46	Epoch: 74	Catergory: transistor	Pixel-AUC: 0.810296	Image-AUC: 0.944583
2022-04-12 00:11:46	Epoch 74 testing end, total 4.41s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:46	Epoch 75[32/170]: loss:0.27148, lr:0.40000, batch time:0.0482, data time:0.1998
2022-04-12 00:11:46	Epoch 75[96/170]: loss:0.26773, lr:0.40000, batch time:0.0500, data time:0.2068
2022-04-12 00:11:47	Epoch 75[160/170]: loss:0.27043, lr:0.40000, batch time:0.0528, data time:0.1909
2022-04-12 00:11:47	Epoch 75 training ends, total 1.28s
2022-04-12 00:11:47	Epoch 75 testing start
2022-04-12 00:11:47	Valid Loss: 0.0033573
2022-04-12 00:11:51	Epoch: 75	Catergory: transistor	Pixel-AUC: 0.794697	Image-AUC: 0.948333
2022-04-12 00:11:51	Epoch 75 testing end, total 4.30s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:52	Epoch 76[32/170]: loss:0.27351, lr:0.40000, batch time:0.0317, data time:0.2008
2022-04-12 00:11:52	Epoch 76[96/170]: loss:0.26915, lr:0.40000, batch time:0.0310, data time:0.1735
2022-04-12 00:11:53	Epoch 76[160/170]: loss:0.27065, lr:0.40000, batch time:0.0552, data time:0.1873
2022-04-12 00:11:53	Epoch 76 training ends, total 1.28s
2022-04-12 00:11:53	Epoch 76 testing start
2022-04-12 00:11:53	Valid Loss: 0.0024863
2022-04-12 00:11:57	Epoch: 76	Catergory: transistor	Pixel-AUC: 0.805290	Image-AUC: 0.946250
2022-04-12 00:11:57	Epoch 76 testing end, total 4.24s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:11:57	Epoch 77[32/170]: loss:0.26987, lr:0.40000, batch time:0.0329, data time:0.1998
2022-04-12 00:11:58	Epoch 77[96/170]: loss:0.26879, lr:0.40000, batch time:0.0595, data time:0.1875
2022-04-12 00:11:58	Epoch 77[160/170]: loss:0.27245, lr:0.40000, batch time:0.0586, data time:0.1892
2022-04-12 00:11:58	Epoch 77 training ends, total 1.30s
2022-04-12 00:11:58	Epoch 77 testing start
2022-04-12 00:11:58	Valid Loss: 0.0017026
2022-04-12 00:12:02	Epoch: 77	Catergory: transistor	Pixel-AUC: 0.812419	Image-AUC: 0.947917
2022-04-12 00:12:02	Epoch 77 testing end, total 4.28s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:03	Epoch 78[32/170]: loss:0.27197, lr:0.40000, batch time:0.0319, data time:0.1991
2022-04-12 00:12:03	Epoch 78[96/170]: loss:0.26397, lr:0.40000, batch time:0.0538, data time:0.2092
2022-04-12 00:12:04	Epoch 78[160/170]: loss:0.26579, lr:0.40000, batch time:0.0536, data time:0.1865
2022-04-12 00:12:04	Epoch 78 training ends, total 1.29s
2022-04-12 00:12:04	Epoch 78 testing start
2022-04-12 00:12:04	Valid Loss: 0.0016189
2022-04-12 00:12:08	Epoch: 78	Catergory: transistor	Pixel-AUC: 0.810284	Image-AUC: 0.945417
2022-04-12 00:12:08	Epoch 78 testing end, total 4.24s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:08	Epoch 79[32/170]: loss:0.26443, lr:0.40000, batch time:0.0310, data time:0.1988
2022-04-12 00:12:09	Epoch 79[96/170]: loss:0.27145, lr:0.40000, batch time:0.0313, data time:0.1877
2022-04-12 00:12:09	Epoch 79[160/170]: loss:0.25665, lr:0.40000, batch time:0.0502, data time:0.1712
2022-04-12 00:12:09	Epoch 79 training ends, total 1.28s
2022-04-12 00:12:09	Epoch 79 testing start
2022-04-12 00:12:10	Valid Loss: 0.0015840
2022-04-12 00:12:14	Epoch: 79	Catergory: transistor	Pixel-AUC: 0.812388	Image-AUC: 0.941667
2022-04-12 00:12:14	Epoch 79 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:14	Epoch 80[32/170]: loss:0.25835, lr:0.40000, batch time:0.0311, data time:0.1996
2022-04-12 00:12:14	Epoch 80[96/170]: loss:0.26059, lr:0.40000, batch time:0.0514, data time:0.1814
2022-04-12 00:12:15	Epoch 80[160/170]: loss:0.25788, lr:0.40000, batch time:0.0507, data time:0.1855
2022-04-12 00:12:15	Epoch 80 training ends, total 1.28s
2022-04-12 00:12:15	Epoch 80 testing start
2022-04-12 00:12:15	Valid Loss: 0.0016901
2022-04-12 00:12:19	Epoch: 80	Catergory: transistor	Pixel-AUC: 0.810059	Image-AUC: 0.940833
2022-04-12 00:12:19	Epoch 80 testing end, total 4.26s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:19	Epoch 81[32/170]: loss:0.25355, lr:0.40000, batch time:0.0311, data time:0.1994
2022-04-12 00:12:20	Epoch 81[96/170]: loss:0.25544, lr:0.40000, batch time:0.0541, data time:0.1867
2022-04-12 00:12:20	Epoch 81[160/170]: loss:0.27761, lr:0.40000, batch time:0.0496, data time:0.1857
2022-04-12 00:12:20	Epoch 81 training ends, total 1.29s
2022-04-12 00:12:20	Epoch 81 testing start
2022-04-12 00:12:21	Valid Loss: 0.0015153
2022-04-12 00:12:25	Epoch: 81	Catergory: transistor	Pixel-AUC: 0.811909	Image-AUC: 0.947500
2022-04-12 00:12:25	Epoch 81 testing end, total 4.39s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:25	Epoch 82[32/170]: loss:0.25841, lr:0.40000, batch time:0.0309, data time:0.2002
2022-04-12 00:12:26	Epoch 82[96/170]: loss:0.25623, lr:0.40000, batch time:0.0502, data time:0.1879
2022-04-12 00:12:26	Epoch 82[160/170]: loss:0.25754, lr:0.40000, batch time:0.0310, data time:0.1860
2022-04-12 00:12:26	Epoch 82 training ends, total 1.28s
2022-04-12 00:12:26	Epoch 82 testing start
2022-04-12 00:12:26	Valid Loss: 0.0014999
2022-04-12 00:12:31	Epoch: 82	Catergory: transistor	Pixel-AUC: 0.812448	Image-AUC: 0.939583
2022-04-12 00:12:31	Epoch 82 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:31	Epoch 83[32/170]: loss:0.26351, lr:0.40000, batch time:0.0312, data time:0.2007
2022-04-12 00:12:31	Epoch 83[96/170]: loss:0.25473, lr:0.40000, batch time:0.0504, data time:0.1871
2022-04-12 00:12:32	Epoch 83[160/170]: loss:0.25524, lr:0.40000, batch time:0.0513, data time:0.1643
2022-04-12 00:12:32	Epoch 83 training ends, total 1.28s
2022-04-12 00:12:32	Epoch 83 testing start
2022-04-12 00:12:32	Valid Loss: 0.0015303
2022-04-12 00:12:36	Epoch: 83	Catergory: transistor	Pixel-AUC: 0.811464	Image-AUC: 0.945417
2022-04-12 00:12:36	Epoch 83 testing end, total 4.25s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:36	Epoch 84[32/170]: loss:0.25492, lr:0.40000, batch time:0.0478, data time:0.2008
2022-04-12 00:12:37	Epoch 84[96/170]: loss:0.25208, lr:0.40000, batch time:0.0525, data time:0.1827
2022-04-12 00:12:37	Epoch 84[160/170]: loss:0.25169, lr:0.40000, batch time:0.0506, data time:0.1861
2022-04-12 00:12:37	Epoch 84 training ends, total 1.27s
2022-04-12 00:12:37	Epoch 84 testing start
2022-04-12 00:12:38	Valid Loss: 0.0013848
2022-04-12 00:12:42	Epoch: 84	Catergory: transistor	Pixel-AUC: 0.813759	Image-AUC: 0.940000
2022-04-12 00:12:42	Epoch 84 testing end, total 4.40s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:42	Epoch 85[32/170]: loss:0.25170, lr:0.40000, batch time:0.0333, data time:0.1995
2022-04-12 00:12:42	Epoch 85[96/170]: loss:0.25533, lr:0.40000, batch time:0.0562, data time:0.1904
2022-04-12 00:12:43	Epoch 85[160/170]: loss:0.24164, lr:0.40000, batch time:0.0529, data time:0.1875
2022-04-12 00:12:43	Epoch 85 training ends, total 1.30s
2022-04-12 00:12:43	Epoch 85 testing start
2022-04-12 00:12:43	Valid Loss: 0.0013762
2022-04-12 00:12:47	Epoch: 85	Catergory: transistor	Pixel-AUC: 0.813542	Image-AUC: 0.946250
2022-04-12 00:12:47	Epoch 85 testing end, total 4.43s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:48	Epoch 86[32/170]: loss:0.24205, lr:0.40000, batch time:0.0517, data time:0.2001
2022-04-12 00:12:48	Epoch 86[96/170]: loss:0.25179, lr:0.40000, batch time:0.0520, data time:0.1899
2022-04-12 00:12:49	Epoch 86[160/170]: loss:0.25580, lr:0.40000, batch time:0.0587, data time:0.1852
2022-04-12 00:12:49	Epoch 86 training ends, total 1.29s
2022-04-12 00:12:49	Epoch 86 testing start
2022-04-12 00:12:49	Valid Loss: 0.0013726
2022-04-12 00:12:53	Epoch: 86	Catergory: transistor	Pixel-AUC: 0.814953	Image-AUC: 0.942500
2022-04-12 00:12:53	Epoch 86 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:54	Epoch 87[32/170]: loss:0.24925, lr:0.40000, batch time:0.0707, data time:0.1997
2022-04-12 00:12:54	Epoch 87[96/170]: loss:0.24526, lr:0.40000, batch time:0.0523, data time:0.1886
2022-04-12 00:12:54	Epoch 87[160/170]: loss:0.25586, lr:0.40000, batch time:0.0321, data time:0.1895
2022-04-12 00:12:55	Epoch 87 training ends, total 1.29s
2022-04-12 00:12:55	Epoch 87 testing start
2022-04-12 00:12:55	Valid Loss: 0.0013766
2022-04-12 00:12:59	Epoch: 87	Catergory: transistor	Pixel-AUC: 0.814491	Image-AUC: 0.943333
2022-04-12 00:12:59	Epoch 87 testing end, total 4.24s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:12:59	Epoch 88[32/170]: loss:0.25111, lr:0.40000, batch time:0.0309, data time:0.1999
2022-04-12 00:13:00	Epoch 88[96/170]: loss:0.25167, lr:0.40000, batch time:0.0534, data time:0.1921
2022-04-12 00:13:00	Epoch 88[160/170]: loss:0.25004, lr:0.40000, batch time:0.0539, data time:0.1827
2022-04-12 00:13:00	Epoch 88 training ends, total 1.29s
2022-04-12 00:13:00	Epoch 88 testing start
2022-04-12 00:13:00	Valid Loss: 0.0013076
2022-04-12 00:13:04	Epoch: 88	Catergory: transistor	Pixel-AUC: 0.813327	Image-AUC: 0.945833
2022-04-12 00:13:04	Epoch 88 testing end, total 4.41s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:05	Epoch 89[32/170]: loss:0.24376, lr:0.40000, batch time:0.0309, data time:0.1999
2022-04-12 00:13:05	Epoch 89[96/170]: loss:0.24832, lr:0.40000, batch time:0.0495, data time:0.1856
2022-04-12 00:13:06	Epoch 89[160/170]: loss:0.25164, lr:0.40000, batch time:0.0522, data time:0.1894
2022-04-12 00:13:06	Epoch 89 training ends, total 1.28s
2022-04-12 00:13:06	Epoch 89 testing start
2022-04-12 00:13:06	Valid Loss: 0.0013761
2022-04-12 00:13:10	Epoch: 89	Catergory: transistor	Pixel-AUC: 0.814508	Image-AUC: 0.944583
2022-04-12 00:13:10	Epoch 89 testing end, total 4.26s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:10	Epoch 90[32/170]: loss:0.24605, lr:0.40000, batch time:0.0480, data time:0.2008
2022-04-12 00:13:11	Epoch 90[96/170]: loss:0.23763, lr:0.40000, batch time:0.0498, data time:0.1851
2022-04-12 00:13:11	Epoch 90[160/170]: loss:0.24455, lr:0.40000, batch time:0.0503, data time:0.1878
2022-04-12 00:13:11	Epoch 90 training ends, total 1.28s
2022-04-12 00:13:11	Epoch 90 testing start
2022-04-12 00:13:12	Valid Loss: 0.0013739
2022-04-12 00:13:16	Epoch: 90	Catergory: transistor	Pixel-AUC: 0.813357	Image-AUC: 0.949583
2022-04-12 00:13:16	Epoch 90 testing end, total 4.24s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:16	Epoch 91[32/170]: loss:0.24787, lr:0.40000, batch time:0.0492, data time:0.1991
2022-04-12 00:13:16	Epoch 91[96/170]: loss:0.24751, lr:0.40000, batch time:0.0501, data time:0.1873
2022-04-12 00:13:17	Epoch 91[160/170]: loss:0.24365, lr:0.40000, batch time:0.0498, data time:0.1858
2022-04-12 00:13:17	Epoch 91 training ends, total 1.28s
2022-04-12 00:13:17	Epoch 91 testing start
2022-04-12 00:13:17	Valid Loss: 0.0013312
2022-04-12 00:13:21	Epoch: 91	Catergory: transistor	Pixel-AUC: 0.813436	Image-AUC: 0.939583
2022-04-12 00:13:21	Epoch 91 testing end, total 4.25s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:21	Epoch 92[32/170]: loss:0.24234, lr:0.40000, batch time:0.0315, data time:0.2016
2022-04-12 00:13:22	Epoch 92[96/170]: loss:0.24579, lr:0.40000, batch time:0.0531, data time:0.1866
2022-04-12 00:13:22	Epoch 92[160/170]: loss:0.25129, lr:0.40000, batch time:0.0538, data time:0.1863
2022-04-12 00:13:22	Epoch 92 training ends, total 1.28s
2022-04-12 00:13:22	Epoch 92 testing start
2022-04-12 00:13:23	Valid Loss: 0.0016643
2022-04-12 00:13:27	Epoch: 92	Catergory: transistor	Pixel-AUC: 0.810627	Image-AUC: 0.944167
2022-04-12 00:13:27	Epoch 92 testing end, total 4.28s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:27	Epoch 93[32/170]: loss:0.25252, lr:0.40000, batch time:0.0332, data time:0.2007
2022-04-12 00:13:27	Epoch 93[96/170]: loss:0.23894, lr:0.40000, batch time:0.0321, data time:0.1898
2022-04-12 00:13:28	Epoch 93[160/170]: loss:0.24387, lr:0.40000, batch time:0.0501, data time:0.2105
2022-04-12 00:13:28	Epoch 93 training ends, total 1.30s
2022-04-12 00:13:28	Epoch 93 testing start
2022-04-12 00:13:28	Valid Loss: 0.0012967
2022-04-12 00:13:32	Epoch: 93	Catergory: transistor	Pixel-AUC: 0.816179	Image-AUC: 0.940833
2022-04-12 00:13:32	Epoch 93 testing end, total 4.44s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:33	Epoch 94[32/170]: loss:0.24370, lr:0.40000, batch time:0.0704, data time:0.2016
2022-04-12 00:13:33	Epoch 94[96/170]: loss:0.24397, lr:0.40000, batch time:0.0317, data time:0.1910
2022-04-12 00:13:34	Epoch 94[160/170]: loss:0.23834, lr:0.40000, batch time:0.0701, data time:0.1906
2022-04-12 00:13:34	Epoch 94 training ends, total 1.30s
2022-04-12 00:13:34	Epoch 94 testing start
2022-04-12 00:13:34	Valid Loss: 0.0013431
2022-04-12 00:13:38	Epoch: 94	Catergory: transistor	Pixel-AUC: 0.816224	Image-AUC: 0.946250
2022-04-12 00:13:38	Epoch 94 testing end, total 4.31s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:38	Epoch 95[32/170]: loss:0.24021, lr:0.40000, batch time:0.0664, data time:0.2003
2022-04-12 00:13:39	Epoch 95[96/170]: loss:0.24510, lr:0.40000, batch time:0.0492, data time:0.1895
2022-04-12 00:13:39	Epoch 95[160/170]: loss:0.23806, lr:0.40000, batch time:0.0507, data time:0.1864
2022-04-12 00:13:39	Epoch 95 training ends, total 1.28s
2022-04-12 00:13:39	Epoch 95 testing start
2022-04-12 00:13:40	Valid Loss: 0.0013946
2022-04-12 00:13:44	Epoch: 95	Catergory: transistor	Pixel-AUC: 0.815745	Image-AUC: 0.946250
2022-04-12 00:13:44	Epoch 95 testing end, total 4.33s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:44	Epoch 96[32/170]: loss:0.23948, lr:0.40000, batch time:0.0310, data time:0.2016
2022-04-12 00:13:44	Epoch 96[96/170]: loss:0.23676, lr:0.40000, batch time:0.0522, data time:0.1887
2022-04-12 00:13:45	Epoch 96[160/170]: loss:0.25102, lr:0.40000, batch time:0.0496, data time:0.1851
2022-04-12 00:13:45	Epoch 96 training ends, total 1.29s
2022-04-12 00:13:45	Epoch 96 testing start
2022-04-12 00:13:45	Valid Loss: 0.0012797
2022-04-12 00:13:49	Epoch: 96	Catergory: transistor	Pixel-AUC: 0.816918	Image-AUC: 0.940000
2022-04-12 00:13:49	Epoch 96 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:50	Epoch 97[32/170]: loss:0.24167, lr:0.40000, batch time:0.0312, data time:0.2005
2022-04-12 00:13:50	Epoch 97[96/170]: loss:0.24110, lr:0.40000, batch time:0.0501, data time:0.1878
2022-04-12 00:13:51	Epoch 97[160/170]: loss:0.23935, lr:0.40000, batch time:0.0501, data time:0.2072
2022-04-12 00:13:51	Epoch 97 training ends, total 1.28s
2022-04-12 00:13:51	Epoch 97 testing start
2022-04-12 00:13:51	Valid Loss: 0.0011778
2022-04-12 00:13:55	Epoch: 97	Catergory: transistor	Pixel-AUC: 0.816754	Image-AUC: 0.945833
2022-04-12 00:13:55	Epoch 97 testing end, total 4.46s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:13:55	Epoch 98[32/170]: loss:0.23239, lr:0.40000, batch time:0.0314, data time:0.2003
2022-04-12 00:13:56	Epoch 98[96/170]: loss:0.23668, lr:0.40000, batch time:0.0523, data time:0.1877
2022-04-12 00:13:56	Epoch 98[160/170]: loss:0.24428, lr:0.40000, batch time:0.0514, data time:0.1860
2022-04-12 00:13:56	Epoch 98 training ends, total 1.28s
2022-04-12 00:13:56	Epoch 98 testing start
2022-04-12 00:13:57	Valid Loss: 0.0011848
2022-04-12 00:14:01	Epoch: 98	Catergory: transistor	Pixel-AUC: 0.818039	Image-AUC: 0.948750
2022-04-12 00:14:01	Epoch 98 testing end, total 4.32s
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2022-04-12 00:14:01	Epoch 99[32/170]: loss:0.24500, lr:0.40000, batch time:0.0314, data time:0.2003
2022-04-12 00:14:01	Epoch 99[96/170]: loss:0.23205, lr:0.40000, batch time:0.0504, data time:0.1880
2022-04-12 00:14:02	Epoch 99[160/170]: loss:0.23857, lr:0.40000, batch time:0.0506, data time:0.1899
2022-04-12 00:14:02	Epoch 99 training ends, total 1.28s
2022-04-12 00:14:02	Epoch 99 testing start
2022-04-12 00:14:02	Valid Loss: 0.0011881
2022-04-12 00:14:06	Epoch: 99	Catergory: transistor	Pixel-AUC: 0.816171	Image-AUC: 0.948333
2022-04-12 00:14:06	Epoch 99 testing end, total 4.36s